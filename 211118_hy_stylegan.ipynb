{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "211118_hy_stylegan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfPvZcyXRqX",
        "outputId": "9447e787-3fd0-4252-cf89-a7b662228a23"
      },
      "source": [
        "# styleGAN은 1.14 나 1.15 (GPU 되는)가 필요함 # downgrade 전 : 2.7.0\n",
        "! pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80eCs5bGXV8y",
        "outputId": "8cfe30f5-aa82-4c78-a683-648f27f6f1a8"
      },
      "source": [
        "! pip install tensorflow-gpu==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "  Downloading tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1 MB 8.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.41.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.19.5)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.13.3)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.12.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (4.8.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.10.0.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9-f6-4MXW0b",
        "outputId": "50386a22-6eee-4a92-9b10-82362000d1fa"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQMn6d0S1C4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a011516-2302-420d-ae6f-df7e1d54d6e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpwjY-2E6g2S",
        "outputId": "fac0f7de-4ed8-491e-ee25-3178421d2527"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMWz0VM8H9r",
        "outputId": "f65b3213-0def-4cc1-f0b3-8300b625fae9"
      },
      "source": [
        "cd MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlBThe2a8Mzs",
        "outputId": "01d395d7-1b68-4c57-831e-8f94168f050a"
      },
      "source": [
        "cd project3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NI7j9CfXaN3",
        "outputId": "aedd40d6-8c5d-4927-8232-51573f341d77"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 89 (delta 0), reused 1 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrDxiUVaXcmi",
        "outputId": "11c35e39-e08c-4779-a808-fe8759c3db89"
      },
      "source": [
        "cd stylegan/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/project3/stylegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROGpNvbfXh0E"
      },
      "source": [
        "# 저장할 디렉토리 생성 (데이터셋 타입 : jpg 파일)\n",
        "!mkdir portraitbig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo_R3ZwQXxK0"
      },
      "source": [
        "# png 파일 담는 곳 \n",
        "!mkdir change "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21oZzNlv8hnk",
        "outputId": "9df54889-93af-4289-e090-3fe657022a28"
      },
      "source": [
        "# cd stylegan/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3/stylegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmWnNJwaXz4J",
        "outputId": "a19bd802-77ab-4d1b-f3b2-9a320dea54f1"
      },
      "source": [
        "cd change/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3/stylegan/change\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI-5adieXz0_"
      },
      "source": [
        "# 변환 위치 만들기\n",
        "import os\n",
        "li = os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOBSWPWB9Io8",
        "outputId": "13c91a7b-47a1-47a9-bb06-7e28f596c047"
      },
      "source": [
        "len(li)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgebcTc8XzyY"
      },
      "source": [
        "# png to jpg \n",
        "cnt = 0\n",
        "import PIL.Image\n",
        "for path in li : \n",
        "  cnt += 1 \n",
        "  rgba_image = PIL.Image.open(path)\n",
        "  rgb_imgae = rgba_image.convert('RGB')\n",
        "  rgb_imgae.save(f'/content/drive/MyDrive/project3/stylegan/portraitbig/{cnt}.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BhLoZ4mXzvi",
        "outputId": "aa4a682a-6199-414c-a9cb-a29a7a9c5d43"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3/stylegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6qIG-BWXzsb",
        "outputId": "8fe30d71-65ef-42f8-bcee-3a40b3617030"
      },
      "source": [
        "# 얼굴 사용이나 사이즈 조절 필요하면 사용 \n",
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.9-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (1.19.5)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz5aJaxIXzp3"
      },
      "source": [
        "!mkdir output # 조절한 거 닮을 곳 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4uwoMBeXzj2",
        "outputId": "adb75cf0-258a-433e-8860-c4ca1e48576f"
      },
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"/content/drive/MyDrive/project3/stylegan/portraitbig/\", \"/content/drive/MyDrive/project3/stylegan/output\", save_format=\"JPEG\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 222 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/project3/stylegan/output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V38n4vgFXzeQ"
      },
      "source": [
        "# 사이즈 설정 \n",
        "p.resize(probability=1.0, width=512, height=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW_XaaLcXzbi"
      },
      "source": [
        "p.random_color(probability=1.0,min_factor=0.5,max_factor=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRiL2ZnwXzVy",
        "outputId": "a84df55c-c3a3-4a3d-950f-f70c41e0385a"
      },
      "source": [
        "p.process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x7F38D836AAD0>: 100%|██████████| 222/222 [00:02<00:00, 77.86 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtz657IzXzS9",
        "outputId": "eb8da547-7820-46e9-b10b-abe78141ff18"
      },
      "source": [
        "p.sample(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x7F38E1DA8590>: 100%|██████████| 100/100 [00:01<00:00, 81.51 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3P6if2-XzQn"
      },
      "source": [
        "from fastai.vision import *\n",
        "verify_images('/content/drive/MyDrive/project3/stylegan/output', delete=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "Rod3iMpwXzN3",
        "outputId": "2badc9b0-51c4-4d84-f0e8-5d73452aa599"
      },
      "source": [
        "!pip install autocrop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocrop\n",
            "  Downloading autocrop-1.1.1.tar.gz (166 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 166 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from autocrop) (1.19.5)\n",
            "Requirement already satisfied: opencv-python<5,>=3 in /usr/local/lib/python3.7/dist-packages (from autocrop) (4.1.2.30)\n",
            "Collecting Pillow~=8.1.0\n",
            "  Downloading Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocrop\n",
            "  Building wheel for autocrop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocrop: filename=autocrop-1.1.1-py3-none-any.whl size=167218 sha256=f2dc1b919ccc36b8fb1f5ef5db5ef2b58d0cd16b5541c279618cb0703e006e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/7e/8e/d40fd78dee1b5e33529d8c580cd544c329e4d94d3486e87bbf\n",
            "Successfully built autocrop\n",
            "Installing collected packages: Pillow, autocrop\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.1.2 autocrop-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K7ukWzHuXzLD",
        "outputId": "3af4fc2d-9420-40e6-fab7-02d0ac89babc"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpa0syoq-8JI",
        "outputId": "fe58ad9a-63b4-4a78-ba33-8deaefcb9ed4"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoHSsGgW_Aen",
        "outputId": "71ef476e-50cb-4240-ee7b-5815b3d1105c"
      },
      "source": [
        "cd MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDtcJs3L_CKk",
        "outputId": "232c1820-9962-4d71-ca3f-0178a9cb490c"
      },
      "source": [
        "cd project3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0LbzT94XzIH",
        "outputId": "834d4f7e-2b66-4893-d4f6-aea1916caf1f"
      },
      "source": [
        "cd stylegan/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3/stylegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5YNPrugXzEu"
      },
      "source": [
        "!mkdir Faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AILtIrU-Yctl"
      },
      "source": [
        "!mkdir Rejects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQVFiJcpYcrO",
        "outputId": "c54931df-e5c9-4084-b6af-0340a2361a17"
      },
      "source": [
        "!autocrop -i /content/drive/MyDrive/project3/stylegan/output/ -o /content/drive/MyDrive/project3/stylegan/Faces/ -w 512 -H 512 --facePercent 50 -r /content/drive/MyDrive/project3/stylegan/Rejects/ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing images in folder: /content/drive/MyDrive/project3/stylegan/output\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_1.jpg_e716ae1f-fb74-459c-9996-030db9e92eef.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_5.jpg_8dce3bd3-acef-44fa-829c-c824fafe5070.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_2.jpg_e0ff4150-79a6-4d18-825f-6e4ef374a56d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_3.jpg_a9964b02-bedb-4160-bb62-6f13879521eb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_7.jpg_9aa3da1b-7e7d-43fa-af95-ecf089351561.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_4.jpg_794fa6f8-c784-4d01-8325-bdd6fb734737.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_8.jpg_e015bcf9-40d8-46f6-aff8-3e3b328d9f5f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_11.jpg_9ffc2caf-fc48-4776-9914-95ee7054ba7d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_6.jpg_c6368916-02ec-4ba4-9f00-c017ca82b9fa.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_12.jpg_3aa442e4-1e0a-4345-b596-f7e11bbfadbf.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_9.jpg_7cadd926-1a67-430a-a12d-f69f9896cbeb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_10.jpg_1d34f20d-dd6c-43a1-99e3-fc3b14102adf.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_14.jpg_a5d4a52c-9b4d-4e20-96a3-d6bcbd56e68a.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_13.jpg_70475ebe-32f6-48ca-b7f8-7e83cdbdfcf4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_15.jpg_48d72105-5012-40e2-999e-1a535d30b1af.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_16.jpg_d035fd42-b2c0-4f9a-b1d3-6164629bb184.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_17.jpg_8b4fc6b6-a9b5-4e18-9d46-2820b2cd6bf3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_19.jpg_ad1ff478-d193-4c3f-9593-e1107ac8a157.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_18.jpg_c22b4b6a-157f-4717-8a48-c079632a726a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_25.jpg_8d0a1f00-47d3-4a4a-90c1-7fa738ab20f1.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_20.jpg_fe956da7-3edb-4792-bde5-b9e48c091065.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_22.jpg_1c6d7241-d7da-4367-a389-111ce17d8612.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_26.jpg_9b4b5d74-8651-4731-b7d0-189857d69de8.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_21.jpg_87852e36-6434-4358-9186-9827d36d8d6f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_31.jpg_c0fee0ee-39aa-4094-8669-fd7df064c9c5.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_24.jpg_66e3a144-b32f-4956-938e-07f9ab1cf25e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_28.jpg_b78cfc29-22cc-4e47-8ea2-fd56e79f1a09.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_29.jpg_ffbd97e1-3a1c-47c1-a228-16c4fb48c13f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_30.jpg_0a725ca8-3c86-42ad-b271-73a345397b1e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_27.jpg_2456b6a9-f4db-4bcd-9599-8214a784dd46.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_33.jpg_43076dc9-c4b8-4f34-b84a-de1329ab7800.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_32.jpg_6e9f9459-d075-44e4-bfe7-cdddc717dcec.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_23.jpg_65955497-9f2e-49b9-9cb1-df56385aca8a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_34.jpg_4ec13523-9b71-4d5c-850d-580c56d15116.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_35.jpg_19887fbe-ebad-4e66-b856-eb3706259e49.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_36.jpg_7e7a473f-108b-4ee1-9e38-074da5c500e2.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_37.jpg_6103b9cb-f7f2-4593-92a7-dd77d2b8923d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_38.jpg_c742201c-19b8-4822-b77b-8cf61ead1a28.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_39.jpg_49db64fe-8476-481c-ad2d-48d859a8d732.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_40.jpg_b585f492-17fd-43d2-8eef-3433e015d9bc.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_41.jpg_ec0941ff-a3e4-4923-8fa1-16c97a67595f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_42.jpg_72121d58-fbe2-4efa-a854-f9caab8b97d7.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_44.jpg_98e83faa-7405-4cb6-9cca-373f00a787f6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_43.jpg_20103577-061f-4f81-b402-0aa0a0e2ee98.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_45.jpg_73479b4c-1b21-4d24-a621-14825ba5a6f9.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_46.jpg_c4567eba-a092-4d5c-9f37-70ab4a1cf68d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_47.jpg_2c570d9a-35e0-4f19-85ea-43767b7736ec.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_50.jpg_5b72e030-fc9a-4f44-81ec-245e3614141d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_48.jpg_6a194ce7-254b-4979-a9ca-57e119bd723a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_51.jpg_e6700864-e343-4a34-a69b-b2c637e097b0.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_52.jpg_b2679748-711b-4e51-8c86-dd03fb025add.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_49.jpg_f4d55d8c-8e36-4040-8a27-f95163ed3d5d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_53.jpg_97b721da-a49d-4a57-8e28-3e2deeb52cc5.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_54.jpg_d3126292-fedb-46d0-be2c-d0b39bd136ea.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_55.jpg_7e4491ce-6c1e-4e0e-aeff-f40cac507883.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_57.jpg_878eb7d3-9666-4cfa-961a-c659cd36fa2c.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_56.jpg_13499e43-70f1-430c-be7d-67db60f81f4d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_60.jpg_73003bdf-ee00-435b-8679-89c12e09c749.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_59.jpg_38f79f66-78b5-4fa2-8777-6c174a33516c.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_61.jpg_c38447f6-6263-4ec9-b6e2-9d6d5609092c.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_62.jpg_8c49daf3-7d04-4cdc-aa2f-52e6717fa3c9.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_63.jpg_b5a8257f-9691-429e-80f9-1171a45cf3f4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_58.jpg_cb03e597-5c4c-4890-a625-cf8095d06325.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_65.jpg_b50650a5-fb00-4b28-a5d4-60d90da8ee54.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_66.jpg_07063953-8f95-4d96-8d6c-dde0f56339c5.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_68.jpg_30a5528c-a7b2-4e1b-a3d5-8c498063e203.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_69.jpg_64530e19-82a2-4a98-af09-f97818279a4b.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_67.jpg_9ae20ebe-7ad0-4f44-af75-7e6465cc23fd.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_72.jpg_3e1cb477-5dfd-4b7a-9ba0-0f7691e3504d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_73.jpg_9f4d2efd-ab8f-4405-a180-b41c90ded46a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_64.jpg_17e9aeee-d3f5-4dc7-9f55-3d35b295b669.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_70.jpg_e3b5c42e-a5fd-4f59-9933-b8977b0ace56.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_74.jpg_1ea46605-f288-418c-9a93-9d40d9d42a29.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_71.jpg_e455f57f-30fb-4da0-b481-2cc88c4be481.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_75.jpg_450bc3a3-6ee1-4c95-8fcb-036b3c95f9c3.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_76.jpg_6dd0c215-5f3b-4a89-a5b9-1252d112cf68.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_79.jpg_614f13e7-f97c-4cc8-b4e9-b78a1660d926.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_77.jpg_842992a9-e3bc-4c66-accd-1649c2e52d38.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_78.jpg_4f54fc7b-6e7e-4d65-875e-267ebb43105c.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_83.jpg_94c0d1c6-fca5-4eab-912c-7f9cc62e8107.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_81.jpg_02a14677-c24f-4d25-9928-f9b865618c4b.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_80.jpg_718e5283-bd4b-49c4-b4d6-4a33cbf63f75.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_84.jpg_a603c288-a8a2-4539-a72c-cb53fae02710.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_82.jpg_c8cf504d-23eb-4405-84af-b5e85272c24f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_85.jpg_34ccd35e-1328-4832-b459-85fabad731e3.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_86.jpg_6164bd83-e5a2-4025-b2a4-2865c5f31ec4.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_87.jpg_9c6ec18f-e53b-43cb-9281-6c76f6dc5ae0.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_88.jpg_430eb568-cd7e-4e0c-8e2f-e344ee412ac2.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_89.jpg_8d6e2a63-19d8-482c-96e8-d5fbcaa2f5dc.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_92.jpg_1fd5d6d8-8e21-44c0-841a-bbf87ad0ecef.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_93.jpg_5ea5d23e-7396-4da3-b951-15498ec7b093.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_91.jpg_2057afa5-e72b-4b03-aad3-9ffe1589281c.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_94.jpg_15a027b8-cbd8-4c21-a2c9-b9e486b27f10.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_90.jpg_2a805f6c-8f89-423f-b4ee-36a801f2eb84.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_98.jpg_0a2d17da-0321-4534-8e16-547eb9b01f03.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_95.jpg_276e39f4-059c-4653-abd4-a4d32415def4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_99.jpg_3c86f57c-f7bb-4616-8330-8619b9f43436.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_97.jpg_5a011540-5731-457b-9b41-e4799c331834.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_96.jpg_226c8181-8630-4d85-b2d0-5bac49f47144.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_100.jpg_9e5013b4-d5f4-42db-9270-be3510c7bee0.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_101.jpg_2bfb09a7-4f8b-47d4-9df3-a27f95ad65c0.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_103.jpg_d10a5456-bf30-425c-b454-645002f72b37.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_104.jpg_9f84f5c1-e3c4-4f62-981b-e8a16f79e6d1.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_105.jpg_f37ec584-4026-4164-bb84-e3085054adc3.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_108.jpg_812fec02-1435-4f75-b051-a9b5bd88b139.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_102.jpg_a7319175-e604-4f60-b9c4-660dfa6dafeb.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_106.jpg_9ce007e3-5fe6-4c1a-9ae6-baac259c2d74.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_109.jpg_28c72b21-27ba-4ec0-a55f-0362949f5898.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_107.jpg_60822575-00a3-4cb4-870d-b53669a08b29.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_110.jpg_fc49938c-11b2-4c6f-bd0d-4a868e5f932d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_111.jpg_b6d5f5f6-7eb5-4c1c-9995-add9bab129a2.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_113.jpg_90c77d5d-3de2-4499-8d60-5df1a09db646.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_112.jpg_20d1efbf-6217-4342-99aa-30f9b2a66ead.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_114.jpg_98802094-659f-49cb-b103-7b6947ae8869.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_117.jpg_5361cc00-2487-4bb9-b9ed-85456fc52e7e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_118.jpg_6339c719-b7fd-4139-b0bf-e50dee07eb8b.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_116.jpg_9b05c4b5-c8b0-49ea-96d0-42aa239766fd.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_115.jpg_9e180327-df26-4407-93b4-2ede324b7da5.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_119.jpg_1121b48d-5837-438f-9714-8691e36ef429.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_121.jpg_69b80319-4fe0-4c09-adea-4cb00e92553f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_120.jpg_aa5105c4-4f47-4262-a540-35ceb1d651ad.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_122.jpg_53daf015-3da8-4d47-a496-1127ab899898.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_125.jpg_cde3c373-e2d8-49f9-9628-ecc507061fe3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_124.jpg_49753f7a-565d-49db-89b2-3eab6142bcb7.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_123.jpg_0afb7b9e-f40c-4bca-ac02-ce509588b0ed.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_126.jpg_662a2f17-f9c7-4779-bbe5-e1fab8bed9e5.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_127.jpg_2765945b-c159-479e-89df-1129bfe18b47.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_128.jpg_9af45cd5-4755-4990-8f4f-b284e6b6d403.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_129.jpg_258a289f-e335-4025-b392-ac4789847165.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_131.jpg_9b3cbb36-6e77-4ec7-adf2-abcb4569bb53.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_130.jpg_768dea14-b0e4-4d0e-b6dd-c25339a85fb7.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_133.jpg_472f22e1-830c-4217-81d5-aadc680e3a22.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_132.jpg_94539b68-a0fd-44ef-b810-e3129af6b42d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_145.jpg_6e8ac840-e619-4c42-9b0a-3bf191ac2947.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_134.jpg_16175c1c-a41d-47b6-88e9-1e0f7c138ae1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_135.jpg_e2f22bab-4ff2-40e2-a46b-708ac6681dd6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_136.jpg_dfacf6a9-7d39-4203-9ff3-2b2ec53a2a53.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_139.jpg_8ff521f5-2fbb-4f90-a785-b5118c38277f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_137.jpg_9093bfb7-afbb-48a8-a485-2546022a09bb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_138.jpg_74ffa961-342c-4970-ac89-6c166a5b95ce.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_140.jpg_e7864259-5dd2-4966-b684-80434d02fdfb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_141.jpg_f279efe6-6c3d-450f-9f1d-93d58052542b.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_142.jpg_268e2300-2329-4905-b730-69da46d0b025.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_143.jpg_66071465-670a-4a35-9a1c-9e84746a60de.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_144.jpg_26e0281e-4a6f-41cf-a873-9019df7f2bfe.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_146.jpg_31515ab5-3553-44eb-affc-95a47875e7c2.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_150.jpg_529d935a-e78c-41aa-a585-f4cb922f0b5d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_149.jpg_bb9b4212-ffa8-4153-8184-dbc467eac7b4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_151.jpg_f91b15cc-cc4c-4eb7-9a0e-202fe299cabc.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_148.jpg_1c77860d-fd53-4566-bbf4-e0af51f9db23.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_153.jpg_43d729d2-e9e3-4edf-bbf2-6b03265bd597.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_147.jpg_6990e9f7-a9b1-4d2c-8e55-03cf6879a005.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_154.jpg_777d502f-80ef-44d6-9dc6-acfee2e62bbe.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_152.jpg_7e5321ed-ea07-47ef-bc7c-e0719d48d5a1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_155.jpg_af6f358e-b10c-4351-b108-a9fd98b74ba7.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_156.jpg_80408437-03e5-43e0-b9de-0cd209893586.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_158.jpg_1fe64b71-007b-4796-b391-cf8db2c3afb7.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_159.jpg_9f325537-3b4c-4980-bc8c-649217fc19e1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_157.jpg_2b2a636b-23a2-40ee-9e85-a6f159e45c80.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_160.jpg_0b4b02f2-db76-4839-9726-3c97d3efe140.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_162.jpg_786c2025-537d-44ae-af3b-a4b1927d8b2c.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_161.jpg_d6ea2b16-ead1-498f-bad4-b8986c796fa1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_163.jpg_fe2976c5-0b75-4fde-b583-a47dd8ad4cd3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_164.jpg_cfc778d3-d82e-471c-b556-506f54ecf5a3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_166.jpg_5e7ccb3c-2c2d-495a-8bfc-4fb2b07c8074.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_165.jpg_de32f80d-e514-49d0-babf-918fcd48e2d1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_167.jpg_0daad119-1e0e-45ac-a474-eec57ff9097d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_168.jpg_b22f8df5-12cd-4953-aef2-4b7fb434bea1.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_169.jpg_5b991260-5381-49fa-adda-7b188738d294.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_171.jpg_b43e97ca-1d69-4091-a959-6d4acbabe6bf.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_170.jpg_fef71ecc-6f14-4ab2-81c8-91e42b6d86db.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_174.jpg_dd7aca42-5749-4b64-a675-b4bad02d8459.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_173.jpg_6165daf0-7824-4ec4-9ee7-1894e6c2b9e4.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_172.jpg_289dc788-1352-4b5a-afc7-c0f481070534.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_175.jpg_2ce75fbe-a134-4090-832a-6cb7c1095dad.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_178.jpg_82ff1bfa-ac78-4e9d-ac65-556e8bbef7f1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_176.jpg_6fffebb8-bd78-4495-a15c-de4abf076d9e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_177.jpg_2f0cc7f9-fbd7-48f4-afe3-c44a865a839a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_180.jpg_f35df53d-c04e-4094-bac7-17422a3eef1c.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_179.jpg_c38c7285-f2ca-4ece-8dd6-d3c298b5dfa1.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_181.jpg_9d5577b1-b71f-462c-a663-20184ec4733f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_182.jpg_ff792aac-9777-4c95-a4b0-efd8a0327263.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_183.jpg_33f29d85-e65b-47b5-8fc1-f70950c5c399.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_184.jpg_3a414d0c-a6f3-4a96-b82a-330384c70f5d.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_185.jpg_38abf952-0c9d-4c17-bd5a-ff1b8d1cbe72.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_186.jpg_572060a6-fba9-492c-a647-097f85314317.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_188.jpg_476cf045-5689-4527-9c9f-6f2a9f155e93.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_187.jpg_b35c29e5-1895-4ce4-b16c-0f2f0f767c8e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_190.jpg_398502f7-aeb0-4b12-bc27-4b25f66454fd.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_189.jpg_73c61908-b8cc-4d3f-8f62-7887fdcf7ad6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_192.jpg_1d3cab3f-dae4-48c9-9a4b-36608651324e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_191.jpg_53e1153a-ecd2-488d-a33d-cf90e726e68f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_193.jpg_dae8c268-698f-4ff5-8831-e5fdea6db66a.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_195.jpg_2f83b563-c5c1-4d3c-ad3d-a91b841de962.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_194.jpg_0c6d1498-b279-4694-a39a-eb96505311f0.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_197.jpg_6de2664e-69ea-4a4a-a373-52dfe71872d0.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_196.jpg_641433af-1540-40c9-a8bb-315d9d183ce3.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_199.jpg_3823e4f0-3480-4571-a211-f576046cc161.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_198.jpg_c35fe7eb-67f4-48d6-960a-85d2ba0a17c6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_200.jpg_feef70ba-3e39-45eb-934e-3554e31f55bb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_201.jpg_56df00ef-86e0-434d-b582-684df8c223ad.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_204.jpg_050fb9ab-f721-4a51-9034-8ca844399c7f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_203.jpg_208a5a5a-8388-4c2c-882f-85298adedb32.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_202.jpg_31115a72-c73c-4125-a824-ebbc9d9b8891.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_206.jpg_643d627b-d35c-4ad9-a3ed-0980d1e9510a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_207.jpg_10395c1e-a891-4243-9127-55edbb9b629b.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_205.jpg_d10cff7b-7ac0-41f6-9461-c840288898ca.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_208.jpg_f07d13b9-81f5-4692-a5cd-3b4eacf7b1bb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_209.jpg_7beaa87d-02e6-47bf-ba9a-e69856d005b6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_210.jpg_aeba5af2-18e8-4299-9e2e-570e57445a87.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_211.jpg_6b5f6e42-f301-4640-9eb7-348399c5f677.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_213.jpg_0c569444-8e2e-4423-974b-c134f7806336.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_212.jpg_f2514e67-52ca-4da5-9163-cef7b8c675a7.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_214.jpg_0a727db8-de4a-45cf-94a4-4e00d54aa5a2.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_216.jpg_9a60123e-4691-489e-bbec-def982ed9d91.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_215.jpg_7e4b8f4b-25b1-49a0-9fdc-556906ab65ec.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_218.jpg_fbdb8adb-1617-4a72-b197-f66fba72be02.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_219.jpg_a4f66ad8-3477-464f-8151-3cb0926dd724.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_217.jpg_5310c981-7805-4f85-a97b-c9e51224ed07.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_221.jpg_61711d80-1a9c-4238-a6a5-04eec9c203f2.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_220.jpg_63ac32ea-cdc8-4d7f-9c62-fd3163a96f1e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_222.jpg_e553ff84-209a-4283-802a-04d462e623c1.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_139.jpg_4a6521ef-6517-485f-9876-14d21e872567.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_150.jpg_a4ae9c00-69bf-47fa-911b-66d91dfdd67a.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_122.jpg_f2f1b6bf-b3ed-468c-ae66-b0dd653b4f3c.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_181.jpg_3965f3e5-cdbb-4679-98ba-05f82010a8a2.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_9.jpg_ec3ac6ae-de31-4006-82bb-8f1baa38767a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_47.jpg_49074ac6-674b-4f2c-a357-d2e5f6a1a733.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_176.jpg_0581c8b0-6569-48fc-b460-d8e6fea80ba4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_20.jpg_460a6935-a6d2-4d10-beaa-f984d93128bc.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_18.jpg_43f49241-0968-419d-9f08-faae59983818.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_119.jpg_0d5d0b48-67a2-464f-9b66-666888e7a157.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_122.jpg_1bdd27c0-5679-4541-9b90-a4f79a5dacf4.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_141.jpg_e4fa3fdc-1a3d-41ac-84ce-dca05581816a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_151.jpg_20fa7015-b886-418a-b675-52176a53fe95.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_9.jpg_3ba93adf-25b0-476c-b95f-cde90e588a1e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_111.jpg_d7d1cf9f-3a4e-4b56-b752-d761351315d5.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_168.jpg_52ee88bc-8a17-4204-b161-5fa73c7d313f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_94.jpg_35421a6f-1fc6-4877-9910-f52cab22552e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_119.jpg_6b51452f-96a8-4663-954d-8b580dc996ae.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_26.jpg_30b4759a-ea7b-42b5-b75d-ae6388e3798b.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_78.jpg_697bca70-6dfd-4b00-8a5e-369366f66351.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_116.jpg_3b17b27b-6014-4570-868d-e23496bbd5b6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_98.jpg_a489713d-ca6f-4cd5-aaa0-c0ac81b6c0f3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_90.jpg_2554e893-203b-4768-9791-be75cd1812ea.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_58.jpg_6f10335e-4381-40cf-9b8c-3aec671b0aad.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_220.jpg_66d21f95-9580-4201-b4f5-07278e57e51c.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_18.jpg_1573459e-6a39-44bd-9db6-fcc6d562a2b8.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_188.jpg_e85f2e73-80b7-4094-93a6-a94280d3b1ba.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_111.jpg_69a1167a-6d27-468c-8d59-cebd3139b8b3.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_216.jpg_3525ad66-fa49-4940-a504-f0430ef448fa.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_52.jpg_cfd290be-bf7d-4dfe-955c-cbd25737cc5a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_39.jpg_97ed191c-a742-4e63-942e-281ea7801a36.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_54.jpg_303afbf4-9e01-4b7d-8c5c-b967abf6e7a8.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_162.jpg_6c13db66-37af-41bb-ad5e-44ed4e86522e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_88.jpg_00ba0d66-f100-4fbe-8a91-1e4e833ccf31.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_169.jpg_cec40452-857a-4f0b-b49b-990d68a1ea2f.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_148.jpg_4e118e32-93f7-4997-82b8-6172b88e3977.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_56.jpg_bdda5b63-842a-4630-ab5f-9fa248a7e4bf.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_163.jpg_21799f36-cf2f-4b46-a906-f981307dacb8.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_130.jpg_499d0c73-69dc-47cb-92b1-d855594d3eb7.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_156.jpg_f56ae984-7963-46c0-8d1e-d82589e1948a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_102.jpg_005b4594-1b55-4c5b-88e2-f7439ee93048.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_119.jpg_828e0c24-cb67-410d-ad4e-38f3271dc3f8.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_221.jpg_75363f90-f208-4821-96f0-1da66022ed7e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_151.jpg_22491af8-2ab4-41bd-ac36-fd48a121cfa0.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_154.jpg_d7f479c2-4000-49a1-aed0-19b0e9f1503f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_190.jpg_7549e99e-710d-4306-8119-e997e5f772ff.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_206.jpg_7793ff91-00ee-443b-9fe6-56f87175b234.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_84.jpg_6e4b47bc-1938-4d3d-b9be-038f0cf40146.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_51.jpg_a037fda4-55c7-41ed-bc32-2955fd95957d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_1.jpg_1d8c954c-d284-4002-9db6-ebf9454a2b16.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_213.jpg_a5d63046-799c-46de-870a-8d10fc601f7a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_71.jpg_113acb13-1cb6-43bd-b46d-4efe61e47137.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_31.jpg_9f63b490-d955-45c0-bb93-edc15f0b489a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_29.jpg_a4bca19c-6534-4579-b29e-2d6e82956eb7.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_138.jpg_bc9cf798-9933-4b40-85ad-72613efea608.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_68.jpg_97eb524f-746d-4cd5-bb06-5b3baf884470.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_68.jpg_0d8e9eb5-40de-415a-b86c-3ccd0ce536bb.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_220.jpg_7a908ef9-fc98-4770-9f0c-54fc71287d2e.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_37.jpg_c0ee645f-0b91-4499-81bb-bd4349232eb7.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_35.jpg_ea5251d1-fedb-45db-9c66-5c7d84019d0d.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_88.jpg_868b841c-a78d-4d71-9162-d5df1406b2aa.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_13.jpg_3aed8776-fbc3-4c3d-9ddc-78ce6b4143a1.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_88.jpg_f3dbbb32-3534-462f-870f-b6adfe67dd14.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_187.jpg_66e3ce9b-2bdc-407c-b8fa-b675ec9cb812.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_201.jpg_88430f79-33a3-4631-8f96-95179a5147b6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_141.jpg_33ffd2af-d6bd-4970-ab5e-1775d9ec8071.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_49.jpg_8c0d3110-371c-429e-860b-d4273f58eefc.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_70.jpg_13bd3cbf-a9a9-45ad-9c9b-e81ae63c0934.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_187.jpg_74300915-77ce-4b05-8729-a05ac6b81ac6.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_58.jpg_a44fd278-2978-49f1-8418-809fed7793ca.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_92.jpg_bd8a8dc9-17b0-47f9-acc9-d79804b0fe79.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_164.jpg_ab7664f4-7af9-4fc5-8d50-f935f57184cd.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_176.jpg_b397ba86-6b83-4dd6-91ba-15923d791a67.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_69.jpg_0cb3945a-5a13-442e-a4d1-1e91713a064e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_58.jpg_51b1e548-b80e-4677-998d-571dee92969f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_33.jpg_2733eca4-744c-4848-8a4a-9d6acd58c667.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_111.jpg_b1ba2db4-a61f-4965-b0d9-be4ba61240b5.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_158.jpg_6d15184a-499b-4054-8d36-b10994fada20.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_199.jpg_9800d4ff-d081-4d3a-bbff-775c4f66ff20.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_41.jpg_3fc27845-ee81-41be-92a3-b9eb1f740c23.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_115.jpg_7c976ab3-ace6-4ff4-92fa-9c599ff8ff11.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_112.jpg_a5c4a49d-7963-4c47-8eb3-8c71001fa2cc.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_198.jpg_d0ed48e0-48a7-41b4-8049-691598e3d647.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_83.jpg_2ce6d010-128f-47ac-bdf5-f4fc8e55c20a.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_153.jpg_c6b6e9fb-3e0f-4ffa-b913-4010c023def8.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_123.jpg_861cf37f-b9a0-4a7b-89ea-515a0bbb7e9f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_181.jpg_97b7c400-35ff-40a1-9b87-1c6ce0297798.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_182.jpg_4ced393e-2943-45db-919b-1074daac1a1e.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_105.jpg_cccb41ef-6eb8-4785-9e5a-f97378c61b40.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_165.jpg_b9dad873-19d1-452a-96ed-b98837a6ad6f.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_174.jpg_f5780d75-2f78-4193-b160-420d72cdf6eb.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_29.jpg_75f6e32d-dc60-419d-9c68-0991f9f80304.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_14.jpg_970b4b08-a77d-4c90-986e-72f0d3b1a295.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_150.jpg_a6374169-6eb4-4eed-b407-c210e650d0ed.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_59.jpg_8cc8ff17-69c8-4006-abd5-bf7b96d06278.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_69.jpg_1964c7ba-40fc-453e-bd5c-13828dc1ff67.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_193.jpg_a9a2f5bb-ef64-4cc8-9dc2-a6d3935c7575.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_106.jpg_ffde7c6d-2b6d-44de-907f-69334fd9f08b.JPEG\n",
            "Face detected:    /content/drive/MyDrive/project3/stylegan/Faces/portraitbig_original_63.jpg_b7394087-b617-4a45-8481-d32c45a6b4ee.JPEG\n",
            "No face detected: /content/drive/MyDrive/project3/stylegan/Rejects/portraitbig_original_142.jpg_bd9339b2-22a8-42ab-b93d-6edc70fa724f.JPEG\n",
            "322 : Input files, 137 : Faces Cropped, 185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFlmBy21YclK",
        "outputId": "633238dc-306f-4b92-d7f8-f6da73293d79"
      },
      "source": [
        "# !gdown https://drive.google.com/uc?id=1cJQtMeTy_QldOP7n64F8stCDXY6Esup9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cJQtMeTy_QldOP7n64F8stCDXY6Esup9\n",
            "To: /content/stylegan/network-snapshot-011125.pkl\n",
            "100% 308M/308M [00:04<00:00, 62.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD8Jd4-_YcgV",
        "outputId": "ca8da63a-2854-4f7c-8282-b675acec848a"
      },
      "source": [
        "!python dataset_tool.py create_from_images datasets/smalls/ /content/drive/MyDrive/project3/stylegan/Faces/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Loading images from \"/content/drive/MyDrive/project3/stylegan/Faces/\"\n",
            "Creating dataset \"datasets/smalls/\"\n",
            "WARNING:tensorflow:From dataset_tool.py:75: The name tf.python_io.TFRecordOptions is deprecated. Please use tf.io.TFRecordOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From dataset_tool.py:75: The name tf.python_io.TFRecordCompressionType is deprecated. Please use tf.compat.v1.python_io.TFRecordCompressionType instead.\n",
            "\n",
            "WARNING:tensorflow:From dataset_tool.py:78: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "dataset_tool.py:87: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 137 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYWyc_GEYceO",
        "outputId": "992d8d4d-4719-4898-aea9-fc5deefe0cb4"
      },
      "source": [
        "cd training/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project3/stylegan/training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI0IxjZzYcbY",
        "outputId": "0e9b6e4a-503b-406f-f300-7006c5a0ed4c"
      },
      "source": [
        "%%writefile training_loop.py \n",
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Main training script.\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "import config\n",
        "import train\n",
        "from training import dataset\n",
        "from training import misc\n",
        "from metrics import metric_base\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Just-in-time processing of training images before feeding them to the networks.\n",
        "\n",
        "def process_reals(x, lod, mirror_augment, drange_data, drange_net):\n",
        "    with tf.name_scope('ProcessReals'):\n",
        "        with tf.name_scope('DynamicRange'):\n",
        "            x = tf.cast(x, tf.float32)\n",
        "            x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
        "        if mirror_augment:\n",
        "            with tf.name_scope('MirrorAugment'):\n",
        "                s = tf.shape(x)\n",
        "                mask = tf.random_uniform([s[0], 1, 1, 1], 0.0, 1.0)\n",
        "                mask = tf.tile(mask, [1, s[1], s[2], s[3]])\n",
        "                x = tf.where(mask < 0.5, x, tf.reverse(x, axis=[3]))\n",
        "        with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
        "            s = tf.shape(x)\n",
        "            y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
        "            y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
        "            y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
        "            y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
        "            x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
        "        with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
        "            s = tf.shape(x)\n",
        "            factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
        "            x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "            x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "            x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "        return x\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Evaluate time-varying training parameters.\n",
        "\n",
        "def training_schedule(\n",
        "    cur_nimg,\n",
        "    training_set,\n",
        "    num_gpus,\n",
        "    lod_initial_resolution  = 4,        # Image resolution used at the beginning.\n",
        "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
        "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
        "    minibatch_base          = 16,       # Maximum minibatch size, divided evenly among GPUs.\n",
        "    minibatch_dict          = {},       # Resolution-specific overrides.\n",
        "    max_minibatch_per_gpu   = {},       # Resolution-specific maximum minibatch size per GPU.\n",
        "    G_lrate_base            = 0.001,    # Learning rate for the generator.\n",
        "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    D_lrate_base            = 0.001,    # Learning rate for the discriminator.\n",
        "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
        "    tick_kimg_base          = 160,      # Default interval of progress snapshots.\n",
        "    tick_kimg_dict          = {4: 160, 8:140, 16:120, 32:100, 64:80, 128:60, 256:40, 512:30, 1024:20}): # Resolution-specific overrides.\n",
        "\n",
        "    # Initialize result dict.\n",
        "    s = dnnlib.EasyDict()\n",
        "    s.kimg = cur_nimg / 1000.0\n",
        "\n",
        "    # Training phase.\n",
        "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
        "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
        "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
        "\n",
        "    # Level-of-detail and resolution.\n",
        "    s.lod = training_set.resolution_log2\n",
        "    s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
        "    s.lod -= phase_idx\n",
        "    if lod_transition_kimg > 0:\n",
        "        s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
        "    s.lod = max(s.lod, 0.0)\n",
        "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
        "\n",
        "    # Minibatch size.\n",
        "    s.minibatch = minibatch_dict.get(s.resolution, minibatch_base)\n",
        "    s.minibatch -= s.minibatch % num_gpus\n",
        "    if s.resolution in max_minibatch_per_gpu:\n",
        "        s.minibatch = min(s.minibatch, max_minibatch_per_gpu[s.resolution] * num_gpus)\n",
        "\n",
        "    # Learning rate.\n",
        "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
        "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
        "    if lrate_rampup_kimg > 0:\n",
        "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
        "        s.G_lrate *= rampup\n",
        "        s.D_lrate *= rampup\n",
        "\n",
        "    # Other parameters.\n",
        "    s.tick_kimg = tick_kimg_dict.get(s.resolution, tick_kimg_base)\n",
        "    return s\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main training script.\n",
        "\n",
        "def training_loop(\n",
        "    submit_config,\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    G_loss_args             = {},       # Options for generator loss.\n",
        "    D_loss_args             = {},       # Options for discriminator loss.\n",
        "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
        "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
        "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
        "    metric_arg_list         = [],       # Options for MetricGroup.\n",
        "    tf_config               = {},       # Options for tflib.init_tf().\n",
        "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
        "    D_repeats               = 1,        # How many times the discriminator is trained per G iteration.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
        "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
        "    total_kimg              = 15000,    # Total length of the training, measured in thousands of real images.\n",
        "    mirror_augment          = False,    # Enable mirror augment?\n",
        "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
        "    image_snapshot_ticks    = 1,        # How often to export image snapshots?\n",
        "    network_snapshot_ticks  = 1,       # How often to export network snapshots?\n",
        "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
        "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
        "    # resume_run_id           = \"/content/stylegan/network-snapshot-011125.pkl\",     # Run ID or network pkl to resume training from, None = start from scratch.\n",
        "    resume_run_id           = None ,\n",
        "    resume_snapshot         = None,     # Snapshot index to resume training from, None = autodetect.\n",
        "    resume_kimg             = 11125,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0):     # Assumed wallclock time at the beginning. Affects reporting.\n",
        "\n",
        "    # Initialize dnnlib and TensorFlow.\n",
        "    ctx = dnnlib.RunContext(submit_config, train)\n",
        "    tflib.init_tf(tf_config)\n",
        "\n",
        "    # Load training set.\n",
        "    training_set = dataset.load_dataset(data_dir=config.data_dir, verbose=True, **dataset_args)\n",
        "\n",
        "    # Construct networks.\n",
        "    with tf.device('/gpu:0'):\n",
        "        if resume_run_id is not None:\n",
        "            network_pkl = misc.locate_network_pkl(resume_run_id, resume_snapshot)\n",
        "            print('Loading networks from \"%s\"...' % network_pkl)\n",
        "            G, D, Gs = misc.load_pkl(network_pkl)\n",
        "        else:\n",
        "            print('Constructing networks...')\n",
        "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "            Gs = G.clone('Gs')\n",
        "    G.print_layers(); D.print_layers()\n",
        "\n",
        "    print('Building TensorFlow graph...')\n",
        "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
        "        lod_in          = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
        "        lrate_in        = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
        "        minibatch_in    = tf.placeholder(tf.int32, name='minibatch_in', shape=[])\n",
        "        minibatch_split = minibatch_in // submit_config.num_gpus\n",
        "        Gs_beta         = 0.5 ** tf.div(tf.cast(minibatch_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
        "\n",
        "    G_opt = tflib.Optimizer(name='TrainG', learning_rate=lrate_in, **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', learning_rate=lrate_in, **D_opt_args)\n",
        "    for gpu in range(submit_config.num_gpus):\n",
        "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
        "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
        "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
        "            lod_assign_ops = [tf.assign(G_gpu.find_var('lod'), lod_in), tf.assign(D_gpu.find_var('lod'), lod_in)]\n",
        "            reals, labels = training_set.get_minibatch_tf()\n",
        "            reals = process_reals(reals, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
        "            with tf.name_scope('G_loss'), tf.control_dependencies(lod_assign_ops):\n",
        "                G_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_split, **G_loss_args)\n",
        "            with tf.name_scope('D_loss'), tf.control_dependencies(lod_assign_ops):\n",
        "                D_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_split, reals=reals, labels=labels, **D_loss_args)\n",
        "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
        "    with tf.device('/gpu:0'):\n",
        "        try:\n",
        "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "        except tf.errors.NotFoundError:\n",
        "            peak_gpu_mem_op = tf.constant(0)\n",
        "\n",
        "    print('Setting up snapshot image grid...')\n",
        "    grid_size, grid_reals, grid_labels, grid_latents = misc.setup_snapshot_image_grid(G, training_set, **grid_args)\n",
        "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
        "\n",
        "    print('Setting up run dir...')\n",
        "    misc.save_image_grid(grid_reals, os.path.join(submit_config.run_dir, 'reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
        "    misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % resume_kimg), drange=drange_net, grid_size=grid_size)\n",
        "    summary_log = tf.summary.FileWriter(submit_config.run_dir)\n",
        "    if save_tf_graph:\n",
        "        summary_log.add_graph(tf.get_default_graph())\n",
        "    if save_weight_histograms:\n",
        "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
        "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
        "\n",
        "    print('Training...\\n')\n",
        "    ctx.update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
        "    maintenance_time = ctx.get_last_update_interval()\n",
        "    cur_nimg = int(resume_kimg * 1000)\n",
        "    cur_tick = 0\n",
        "    tick_start_nimg = cur_nimg\n",
        "    prev_lod = -1.0\n",
        "    while cur_nimg < total_kimg * 1000:\n",
        "        if ctx.should_stop(): break\n",
        "\n",
        "        # Choose training parameters and configure training ops.\n",
        "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
        "        training_set.configure(sched.minibatch // submit_config.num_gpus, sched.lod)\n",
        "        if reset_opt_for_new_lod:\n",
        "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
        "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
        "        prev_lod = sched.lod\n",
        "\n",
        "        # Run training ops.\n",
        "        for _mb_repeat in range(minibatch_repeats):\n",
        "            for _D_repeat in range(D_repeats):\n",
        "                tflib.run([D_train_op, Gs_update_op], {lod_in: sched.lod, lrate_in: sched.D_lrate, minibatch_in: sched.minibatch})\n",
        "                cur_nimg += sched.minibatch\n",
        "            tflib.run([G_train_op], {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_in: sched.minibatch})\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000)\n",
        "        if cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_time = ctx.get_time_since_last_update()\n",
        "            total_time = ctx.get_time_since_start() + resume_time\n",
        "\n",
        "            # Report progress.\n",
        "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %-4.1f' % (\n",
        "                autosummary('Progress/tick', cur_tick),\n",
        "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
        "                autosummary('Progress/lod', sched.lod),\n",
        "                autosummary('Progress/minibatch', sched.minibatch),\n",
        "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
        "                autosummary('Timing/sec_per_tick', tick_time),\n",
        "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
        "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
        "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "\n",
        "            # Save snapshots.\n",
        "            if cur_tick % image_snapshot_ticks == 0 or done:\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
        "                misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % (cur_nimg // 1000)), drange=drange_net, grid_size=grid_size)\n",
        "            if cur_tick % network_snapshot_ticks == 0 or done or cur_tick == 1:\n",
        "                pkl = os.path.join(submit_config.run_dir, 'network-snapshot-%06d.pkl' % (cur_nimg // 1000))\n",
        "                misc.save_pkl((G, D, Gs), pkl)\n",
        "                metrics.run(pkl, run_dir=submit_config.run_dir, num_gpus=submit_config.num_gpus, tf_config=tf_config)\n",
        "\n",
        "            # Update summaries and RunContext.\n",
        "            metrics.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            ctx.update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
        "            maintenance_time = ctx.get_last_update_interval() - tick_time\n",
        "\n",
        "    # Write final results.\n",
        "    misc.save_pkl((G, D, Gs), os.path.join(submit_config.run_dir, 'network-final.pkl'))\n",
        "    summary_log.close()\n",
        "\n",
        "    ctx.close()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting training_loop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbGJL9JvYcZE",
        "outputId": "674634a9-8264-43ae-f920-36b6f073db81"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/project3/stylegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRUXooLkYcWG",
        "outputId": "bbc14970-8b5a-472d-f62d-5d26a5498b15"
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Main entry point for training StyleGAN and ProGAN networks.\"\"\"\n",
        "\n",
        "import copy\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "\n",
        "import config\n",
        "from metrics import metric_base\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Official training configs for StyleGAN, targeted mainly for FFHQ.\n",
        "\n",
        "if 1:\n",
        "    desc          = 'sgan'                                                                 # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop')         # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_stylegan.G_style')               # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_stylegan.D_basic')               # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_logistic_nonsaturating')           # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_logistic_simplegp', r1_gamma=10.0) # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                             # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                             # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='4k', layout='random')                                   # Options for setup_snapshot_image_grid().\n",
        "    #metrics       = [metric_base.fid50k]                                                   # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                                  # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                           # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset.\n",
        "    desc += '-custom';     dataset = EasyDict(tfrecord_dir='smalls');              train.mirror_augment = True\n",
        "    #desc += '-celebahq'; dataset = EasyDict(tfrecord_dir='celebahq');          train.mirror_augment = True\n",
        "    #desc += '-bedroom';  dataset = EasyDict(tfrecord_dir='lsun-bedroom-full'); train.mirror_augment = False\n",
        "    #desc += '-car';      dataset = EasyDict(tfrecord_dir='lsun-car-512x384');  train.mirror_augment = False\n",
        "    #desc += '-cat';      dataset = EasyDict(tfrecord_dir='lsun-cat-full');     train.mirror_augment = False\n",
        "\n",
        "    # Number of GPUs.\n",
        "    desc += '-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}\n",
        "    #desc += '-2gpu'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}\n",
        "    #desc += '-4gpu'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
        "    #desc += '-8gpu'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
        "\n",
        "    # Default options.\n",
        "    train.total_kimg = 25000\n",
        "    sched.lod_initial_resolution = 8\n",
        "    sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
        "    sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
        "\n",
        "    # WGAN-GP loss for CelebA-HQ.\n",
        "    #desc += '-wgangp'; G_loss = EasyDict(func_name='training.loss.G_wgan'); D_loss = EasyDict(func_name='training.loss.D_wgan_gp'); sched.G_lrate_dict = {k: min(v, 0.002) for k, v in sched.G_lrate_dict.items()}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
        "\n",
        "    # Table 1.\n",
        "    #desc += '-tuned-baseline'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-add-mapping-and-styles'; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-remove-traditional-input'; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-add-noise-inputs'; G.style_mixing_prob = 0.0\n",
        "    #desc += '-mixing-regularization' # default\n",
        "\n",
        "    # Table 2.\n",
        "    #desc += '-mix0'; G.style_mixing_prob = 0.0\n",
        "    #desc += '-mix50'; G.style_mixing_prob = 0.5\n",
        "    #desc += '-mix90'; G.style_mixing_prob = 0.9 # default\n",
        "    #desc += '-mix100'; G.style_mixing_prob = 1.0\n",
        "\n",
        "    # Table 4.\n",
        "    #desc += '-traditional-0'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-traditional-8'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 8; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
        "    #desc += '-stylebased-0'; G.mapping_layers = 0\n",
        "    #desc += '-stylebased-1'; G.mapping_layers = 1\n",
        "    #desc += '-stylebased-2'; G.mapping_layers = 2\n",
        "    #desc += '-stylebased-8'; G.mapping_layers = 8 # default\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Official training configs for Progressive GAN, targeted mainly for CelebA-HQ.\n",
        "\n",
        "if 0:\n",
        "    desc          = 'pgan'                                                         # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_progan.G_paper')         # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_progan.D_paper')         # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_wgan')                     # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_wgan_gp')                  # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                     # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='1080p', layout='random')                        # Options for setup_snapshot_image_grid().\n",
        "    #metrics       = [metric_base.fid50k]                                           # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset (choose one).\n",
        "    #desc += '-celebahq';            dataset = EasyDict(tfrecord_dir='celebahq'); train.mirror_augment = True\n",
        "    #desc += '-celeba';              dataset = EasyDict(tfrecord_dir='celeba'); train.mirror_augment = True\n",
        "    #desc += '-cifar10';             dataset = EasyDict(tfrecord_dir='cifar10')\n",
        "    #desc += '-cifar100';            dataset = EasyDict(tfrecord_dir='cifar100')\n",
        "    #desc += '-svhn';                dataset = EasyDict(tfrecord_dir='svhn')\n",
        "    #desc += '-mnist';               dataset = EasyDict(tfrecord_dir='mnist')\n",
        "    #desc += '-mnistrgb';            dataset = EasyDict(tfrecord_dir='mnistrgb')\n",
        "    #desc += '-syn1024rgb';          dataset = EasyDict(class_name='training.dataset.SyntheticDataset', resolution=1024, num_channels=3)\n",
        "    #desc += '-lsun-airplane';       dataset = EasyDict(tfrecord_dir='lsun-airplane-100k');       train.mirror_augment = True\n",
        "    #desc += '-lsun-bedroom';        dataset = EasyDict(tfrecord_dir='lsun-bedroom-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-bicycle';        dataset = EasyDict(tfrecord_dir='lsun-bicycle-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-bird';           dataset = EasyDict(tfrecord_dir='lsun-bird-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-boat';           dataset = EasyDict(tfrecord_dir='lsun-boat-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-bottle';         dataset = EasyDict(tfrecord_dir='lsun-bottle-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-bridge';         dataset = EasyDict(tfrecord_dir='lsun-bridge-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-bus';            dataset = EasyDict(tfrecord_dir='lsun-bus-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-car';            dataset = EasyDict(tfrecord_dir='lsun-car-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-cat';            dataset = EasyDict(tfrecord_dir='lsun-cat-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-chair';          dataset = EasyDict(tfrecord_dir='lsun-chair-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-churchoutdoor';  dataset = EasyDict(tfrecord_dir='lsun-churchoutdoor-100k');  train.mirror_augment = True\n",
        "    #desc += '-lsun-classroom';      dataset = EasyDict(tfrecord_dir='lsun-classroom-100k');      train.mirror_augment = True\n",
        "    #desc += '-lsun-conferenceroom'; dataset = EasyDict(tfrecord_dir='lsun-conferenceroom-100k'); train.mirror_augment = True\n",
        "    #desc += '-lsun-cow';            dataset = EasyDict(tfrecord_dir='lsun-cow-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-diningroom';     dataset = EasyDict(tfrecord_dir='lsun-diningroom-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-diningtable';    dataset = EasyDict(tfrecord_dir='lsun-diningtable-100k');    train.mirror_augment = True\n",
        "    #desc += '-lsun-dog';            dataset = EasyDict(tfrecord_dir='lsun-dog-100k');            train.mirror_augment = True\n",
        "    #desc += '-lsun-horse';          dataset = EasyDict(tfrecord_dir='lsun-horse-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-kitchen';        dataset = EasyDict(tfrecord_dir='lsun-kitchen-100k');        train.mirror_augment = True\n",
        "    #desc += '-lsun-livingroom';     dataset = EasyDict(tfrecord_dir='lsun-livingroom-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-motorbike';      dataset = EasyDict(tfrecord_dir='lsun-motorbike-100k');      train.mirror_augment = True\n",
        "    #desc += '-lsun-person';         dataset = EasyDict(tfrecord_dir='lsun-person-100k');         train.mirror_augment = True\n",
        "    #desc += '-lsun-pottedplant';    dataset = EasyDict(tfrecord_dir='lsun-pottedplant-100k');    train.mirror_augment = True\n",
        "    #desc += '-lsun-restaurant';     dataset = EasyDict(tfrecord_dir='lsun-restaurant-100k');     train.mirror_augment = True\n",
        "    #desc += '-lsun-sheep';          dataset = EasyDict(tfrecord_dir='lsun-sheep-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-sofa';           dataset = EasyDict(tfrecord_dir='lsun-sofa-100k');           train.mirror_augment = True\n",
        "    #desc += '-lsun-tower';          dataset = EasyDict(tfrecord_dir='lsun-tower-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-train';          dataset = EasyDict(tfrecord_dir='lsun-train-100k');          train.mirror_augment = True\n",
        "    #desc += '-lsun-tvmonitor';      dataset = EasyDict(tfrecord_dir='lsun-tvmonitor-100k');      train.mirror_augment = True\n",
        "\n",
        "    # Conditioning & snapshot options.\n",
        "    #desc += '-cond'; dataset.max_label_size = 'full' # conditioned on full label\n",
        "    #desc += '-cond1'; dataset.max_label_size = 1 # conditioned on first component of the label\n",
        "    #desc += '-g4k'; grid.size = '4k'\n",
        "    #desc += '-grpc'; grid.layout = 'row_per_class'\n",
        "\n",
        "    # Config presets (choose one).\n",
        "    #desc += '-preset-v1-1gpu'; submit_config.num_gpus = 1; D.mbstd_group_size = 16; sched.minibatch_base = 16; sched.minibatch_dict = {256: 14, 512: 6, 1024: 3}; sched.lod_training_kimg = 800; sched.lod_transition_kimg = 800; train.total_kimg = 19000\n",
        "    #desc += '-preset-v2-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}; sched.G_lrate_dict = {1024: 0.0015}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-2gpus'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}; sched.G_lrate_dict = {512: 0.0015, 1024: 0.002}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-4gpus'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}; sched.G_lrate_dict = {256: 0.0015, 512: 0.002, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-8gpus'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}; sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "\n",
        "    # Numerical precision (choose one).\n",
        "    #desc += '-fp32'; sched.max_minibatch_per_gpu = {256: 16, 512: 8, 1024: 4}\n",
        "    #desc += '-fp16'; G.dtype = 'float16'; D.dtype = 'float16'; G.pixelnorm_epsilon=1e-4; G_opt.use_loss_scaling = True; D_opt.use_loss_scaling = True; sched.max_minibatch_per_gpu = {512: 16, 1024: 8}\n",
        "\n",
        "    # Disable individual features.\n",
        "    #desc += '-nogrowing'; sched.lod_initial_resolution = 1024; sched.lod_training_kimg = 0; sched.lod_transition_kimg = 0; train.total_kimg = 10000\n",
        "    #desc += '-nopixelnorm'; G.use_pixelnorm = False\n",
        "    #desc += '-nowscale'; G.use_wscale = False; D.use_wscale = False\n",
        "    #desc += '-noleakyrelu'; G.use_leakyrelu = False\n",
        "    #desc += '-nosmoothing'; train.G_smoothing_kimg = 0.0\n",
        "    #desc += '-norepeat'; train.minibatch_repeats = 1\n",
        "    #desc += '-noreset'; train.reset_opt_for_new_lod = False\n",
        "\n",
        "    # Special modes.\n",
        "    #desc += '-BENCHMARK'; sched.lod_initial_resolution = 4; sched.lod_training_kimg = 3; sched.lod_transition_kimg = 3; train.total_kimg = (8*2+1)*3; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-BENCHMARK0'; sched.lod_initial_resolution = 1024; train.total_kimg = 10; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-VERBOSE'; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1; train.network_snapshot_ticks = 100\n",
        "    #desc += '-GRAPH'; train.save_tf_graph = True\n",
        "    #desc += '-HIST'; train.save_weight_histograms = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main entry point for training.\n",
        "# Calls the function indicated by 'train' using the selected options.\n",
        "\n",
        "def main():\n",
        "    kwargs = EasyDict(train)\n",
        "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "    kwargs.update(dataset_args=dataset, sched_args=sched, grid_args=grid, tf_config=tf_config)\n",
        "    kwargs.submit_config = copy.deepcopy(submit_config)\n",
        "    kwargs.submit_config.run_dir_root = dnnlib.submission.submit.get_template_from_path(config.result_dir)\n",
        "    kwargs.submit_config.run_dir_ignore += config.run_dir_ignore\n",
        "    kwargs.submit_config.run_desc = desc\n",
        "    dnnlib.submit_run(**kwargs)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the run dir root: results\n",
            "Creating the run dir: results/00000-sgan-custom-1gpu\n",
            "Copying files to the run dir\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:75: The name tf.python_io.TFRecordOptions is deprecated. Please use tf.io.TFRecordOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:75: The name tf.python_io.TFRecordCompressionType is deprecated. Please use tf.compat.v1.python_io.TFRecordCompressionType instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:76: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:132: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:132: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/dataset.py:132: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "Dataset shape = [3, 512, 512]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/PixelNorm           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 16, 512)        -               \n",
            "Truncation                    -         (?, 16, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         534528    (?, 512, 4, 4)      (512,)          \n",
            "G_synthesis/4x4/Conv          2885632   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod7        1539      (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod6        1539      (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D         -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/Grow_lod6         -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/16x16/Conv0_up    2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod5        1539      (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_1       -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/Grow_lod5         -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/32x32/Conv0_up    2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod4        1539      (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_2       -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/Grow_lod4         -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/64x64/Conv0_up    1442816   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
            "G_synthesis/64x64/Conv1       852992    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
            "G_synthesis/ToRGB_lod3        771       (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
            "G_synthesis/Upscale2D_3       -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/Grow_lod3         -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/128x128/Conv0_up  426496    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
            "G_synthesis/128x128/Conv1     279040    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
            "G_synthesis/ToRGB_lod2        387       (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
            "G_synthesis/Upscale2D_4       -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/Grow_lod2         -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/256x256/Conv0_up  139520    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
            "G_synthesis/256x256/Conv1     102656    (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
            "G_synthesis/ToRGB_lod1        195       (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
            "G_synthesis/Upscale2D_5       -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/Grow_lod1         -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/512x512/Conv0_up  51328     (?, 32, 512, 512)   (3, 3, 64, 32)  \n",
            "G_synthesis/512x512/Conv1     42112     (?, 32, 512, 512)   (3, 3, 32, 32)  \n",
            "G_synthesis/ToRGB_lod0        99        (?, 3, 512, 512)    (1, 1, 32, 3)   \n",
            "G_synthesis/Upscale2D_6       -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/Grow_lod0         -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/lod               -         ()                  -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise13           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n",
            "G_synthesis/noise15           -         (1, 1, 512, 512)    -               \n",
            "images_out                    -         (?, 3, 512, 512)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         26179768                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "lod                  -         ()                  -               \n",
            "FromRGB_lod0         128       (?, 32, 512, 512)   (1, 1, 3, 32)   \n",
            "512x512/Conv0        9248      (?, 32, 512, 512)   (3, 3, 32, 32)  \n",
            "512x512/Conv1_down   18496     (?, 64, 256, 256)   (3, 3, 32, 64)  \n",
            "Downscale2D          -         (?, 3, 256, 256)    -               \n",
            "FromRGB_lod1         256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
            "Grow_lod0            -         (?, 64, 256, 256)   -               \n",
            "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
            "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
            "Downscale2D_1        -         (?, 3, 128, 128)    -               \n",
            "FromRGB_lod2         512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
            "Grow_lod1            -         (?, 128, 128, 128)  -               \n",
            "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
            "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
            "Downscale2D_2        -         (?, 3, 64, 64)      -               \n",
            "FromRGB_lod3         1024      (?, 256, 64, 64)    (1, 1, 3, 256)  \n",
            "Grow_lod2            -         (?, 256, 64, 64)    -               \n",
            "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
            "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
            "Downscale2D_3        -         (?, 3, 32, 32)      -               \n",
            "FromRGB_lod4         2048      (?, 512, 32, 32)    (1, 1, 3, 512)  \n",
            "Grow_lod3            -         (?, 512, 32, 32)    -               \n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "Downscale2D_4        -         (?, 3, 16, 16)      -               \n",
            "FromRGB_lod5         2048      (?, 512, 16, 16)    (1, 1, 3, 512)  \n",
            "Grow_lod4            -         (?, 512, 16, 16)    -               \n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "Downscale2D_5        -         (?, 3, 8, 8)        -               \n",
            "FromRGB_lod6         2048      (?, 512, 8, 8)      (1, 1, 3, 512)  \n",
            "Grow_lod5            -         (?, 512, 8, 8)      -               \n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "Downscale2D_6        -         (?, 3, 4, 4)        -               \n",
            "FromRGB_lod7         2048      (?, 512, 4, 4)      (1, 1, 3, 512)  \n",
            "Grow_lod6            -         (?, 512, 4, 4)      -               \n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "4x4/Dense1           513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                23080225                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/training_loop.py:168: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/util.py:242: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/networks_stylegan.py:90: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/optimizer.py:98: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Setting up snapshot image grid...\n",
            "Setting up run dir...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/training/training_loop.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Training...\n",
            "\n",
            "tick 1     kimg 11155.0  lod 0.00  minibatch 4    time 1h 28m 13s   sec/tick 5235.2  sec/kimg 174.51  maintenance 58.2   gpumem 5.6 \n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/autosummary.py:137: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/project3/stylegan/dnnlib/tflib/autosummary.py:182: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "tick 2     kimg 11185.0  lod 0.00  minibatch 4    time 2h 55m 57s   sec/tick 5247.4  sec/kimg 174.91  maintenance 15.7   gpumem 5.6 \n",
            "tick 3     kimg 11215.0  lod 0.00  minibatch 4    time 4h 23m 37s   sec/tick 5255.5  sec/kimg 175.18  maintenance 5.0    gpumem 5.6 \n",
            "tick 4     kimg 11245.0  lod 0.00  minibatch 4    time 5h 51m 13s   sec/tick 5251.3  sec/kimg 175.04  maintenance 4.8    gpumem 5.6 \n",
            "tick 5     kimg 11275.0  lod 0.00  minibatch 4    time 7h 18m 39s   sec/tick 5241.7  sec/kimg 174.72  maintenance 4.5    gpumem 5.6 \n",
            "tick 6     kimg 11305.0  lod 0.00  minibatch 4    time 8h 46m 10s   sec/tick 5245.3  sec/kimg 174.84  maintenance 5.2    gpumem 5.6 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDRV6rQbYcTU"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "import moviepy.editor as mpy\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "tflib.init_tf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD0SkoB1YcQ6",
        "outputId": "6ead8dfd-9ba1-484c-bb70-6a820433d747"
      },
      "source": [
        "model = '/content/drive/MyDrive/network-snapshot-011215.pkl'\n",
        "\n",
        "with open(model, 'rb') as f:\n",
        "    _G, _D, Gs = pickle.load(f)\n",
        "\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <string>:373: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFbbGH3xYcOE"
      },
      "source": [
        "truncation = 0.7\n",
        "\n",
        "\n",
        "def bookmark(latents, new_faves):\n",
        "    for f in new_faves:\n",
        "        faves.append(latents[f])\n",
        "\n",
        "def show_faves(faves):\n",
        "    latents = np.array(faves)\n",
        "    labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "    n = len(faves)\n",
        "    nr, nc = math.ceil(n / 6), 6\n",
        "    for r in range(nr):\n",
        "        images = Gs.run(latents[6*r:min(n-1, 6*(r+1))], None, truncation_psi=truncation, randomize_noise=False, output_transform=fmt)\n",
        "        img1 = np.concatenate([img for img in images], axis=1)\n",
        "        plt.figure(figsize=(24,4))\n",
        "        plt.imshow(img1)\n",
        "        \n",
        "def random_sample(num_images, scale):\n",
        "    latents = np.random.RandomState(int(1000*random.random())).randn(num_images, *Gs.input_shapes[0][1:])\n",
        "    labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "    images = Gs.run(latents, None, truncation_psi=truncation, randomize_noise=False, output_transform=fmt)\n",
        "    images_ct = np.concatenate([img for img in images], axis=1)\n",
        "    plt.figure(figsize=(scale*num_images, scale))\n",
        "    plt.imshow(images_ct)\n",
        "    return images, latents\n",
        "\n",
        "def get_latent_interpolation(endpoints, num_frames_per, mode, shuffle):\n",
        "    if shuffle:\n",
        "        random.shuffle(endpoints)\n",
        "    num_endpoints, dim = len(endpoints), len(endpoints[0])\n",
        "    num_frames = num_frames_per * num_endpoints\n",
        "    endpoints = np.array(endpoints)\n",
        "    latents = np.zeros((num_frames, dim))\n",
        "    for e in range(num_endpoints):\n",
        "        e1, e2 = e, (e+1)%num_endpoints\n",
        "        for t in range(num_frames_per):\n",
        "            frame = e * num_frames_per + t\n",
        "            r = 0.5 - 0.5 * np.cos(np.pi*t/(num_frames_per-1)) if mode == 'ease' else float(t) / num_frames_per\n",
        "            latents[frame, :] = (1.0-r) * endpoints[e1,:] + r * endpoints[e2,:]\n",
        "    return latents\n",
        "\n",
        "def get_latent_interpolation_bspline(endpoints, nf, k, s, shuffle):\n",
        "    if shuffle:\n",
        "        random.shuffle(endpoints)\n",
        "    x = np.array(endpoints)\n",
        "    x = np.append(x, x[0,:].reshape(1, x.shape[1]), axis=0)\n",
        "    nd = x.shape[1]\n",
        "    latents = np.zeros((nd, nf))\n",
        "    nss = list(range(1, 10)) + [10]*(nd-19) + list(range(10,0,-1))\n",
        "    for i in tqdm(range(nd-9)):\n",
        "        idx = list(range(i,i+10))\n",
        "        tck, u = interpolate.splprep([x[:,j] for j in range(i,i+10)], k=k, s=s)\n",
        "        out = interpolate.splev(np.linspace(0, 1, num=nf, endpoint=True), tck)\n",
        "        latents[i:i+10,:] += np.array(out)\n",
        "    latents = latents / np.array(nss).reshape((512,1))\n",
        "    return latents.T\n",
        "\n",
        "\n",
        "def generate_images(latents, labels):\n",
        "    batch_size = 8\n",
        "    num_frames = latents.shape[0]\n",
        "    num_batches = int(np.ceil(num_frames/batch_size))\n",
        "    images = []\n",
        "    for b in tqdm(range(num_batches)):\n",
        "        new_images = Gs.run(latents[b*batch_size:min((b+1)*batch_size, num_frames-1), :], None, truncation_psi=truncation, randomize_noise=False, output_transform=fmt)\n",
        "        for img in new_images:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "def make_movie(images, out_dir, out_name):\n",
        "    temp_dir = 'frames%06d'%int(1000000*random.random())\n",
        "    os.system('mkdir %s'%temp_dir)\n",
        "    for idx in tqdm(range(len(images))):\n",
        "        PIL.Image.fromarray(images[idx], 'RGB').save('%s/frame%05d.png' % (temp_dir, idx))\n",
        "    cmd = 'ffmpeg -i %s/frame%05d.png -c:v libx264 -pix_fmt yuv420p %s/%s.mp4' % (temp_dir, out_dir, out_name)\n",
        "    print(cmd)\n",
        "    os.system(cmd)\n",
        "    os.system('rm -rf %s'%temp_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe-1ElZ5YcLI"
      },
      "source": [
        "#from google.colab import files\n",
        "\n",
        "def random_sample(num_images, scale):\n",
        "    latents = np.random.RandomState(int(1000*random.random())).randn(num_images, *Gs.input_shapes[0][1:])\n",
        "    labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "    images = Gs.run(latents, None, truncation_psi=truncation, randomize_noise=False, output_transform=fmt)\n",
        "    images_ct = np.concatenate([img for img in images], axis=1)\n",
        "    plt.figure(figsize=(scale*num_images, scale))\n",
        "    plt.imshow(images_ct)\n",
        "    plt.axis('off')\n",
        "    #plt.savefig('download.png')\n",
        "    return images, latents\n",
        "\n",
        "images, latents = random_sample(40, scale=8)\n",
        "\n",
        "\n",
        "#files.download('download.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsLCfQLyYvJi"
      },
      "source": [
        "latents = get_latent_interpolation(latents, 30, 'linear', False)\n",
        "labels = np.zeros([latents.shape[0]] + Gs.input_shapes[1][1:])\n",
        "\n",
        "images = generate_images(latents, labels)    \n",
        "\n",
        "make_movie(images, '.', 'faves13')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUkvbDYLYvGT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwjJX_LHYu44"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}